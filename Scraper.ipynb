{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "import ssl\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "waitTime = 2 # Time in seconds between web reqeust\n",
    "state_id = {'Assam':{'url':'https://results.eci.gov.in/Result2021/ConstituencywiseS03{}.htm',\n",
    "                    'id':'S03'},\n",
    "           'Kerala':{'url':'https://results.eci.gov.in/Result2021/ConstituencywiseS11{}.htm',\n",
    "                    'id':'S11'},\n",
    "           'Puducherry':{'url':'https://results.eci.gov.in/Result2021/ConstituencywiseU07{}.htm',\n",
    "                    'id':'U07'},\n",
    "           'Tamil Nadu':{'url':'https://results.eci.gov.in/Result2021/ConstituencywiseS22{}.htm',\n",
    "                    'id':'S22'},\n",
    "           'West Bengal':{'url':'https://results.eci.gov.in/Result2021/ConstituencywiseS25{}.htm',\n",
    "                    'id':'S25'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_page(url):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    req = Request(url, headers=hdr)\n",
    "    gcontext = ssl.SSLContext()\n",
    "    page = urlopen(req, context=gcontext)\n",
    "    soup = BeautifulSoup(page, \"html.parser\", from_encoding=\"utf-8\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_constituencyid(state_id):\n",
    "    constituencyid = {}\n",
    "    # Download any one page to get all ids\n",
    "    state_names = list(state_id.keys())\n",
    "    soup = download_page(state_id[state_names[0]]['url'].format(1))\n",
    "    for state in state_id:\n",
    "        id_names = soup.find(\"input\", {\"id\": state_id[state]['id']}).get('value')\n",
    "        id_names = id_names.strip().split(';')\n",
    "        constituencyid[state] = {}\n",
    "        for id_name in id_names:\n",
    "            # Last element is empty handle it with if condition\n",
    "            if id_name != '':\n",
    "                cid, name = id_name.split(',')\n",
    "                cid = int(cid)\n",
    "                name = name.strip()\n",
    "                constituencyid[state][cid] = name\n",
    "    return constituencyid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_url(base_url, cid):\n",
    "    base_url = base_url.format(cid)\n",
    "    url = \"{}?ac={}\".format(base_url, cid)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_content(page_content, cid, cname):\n",
    "    # Get the main result table using its style\n",
    "    table_style = 'margin: auto; width: 100%; font-family: Verdana; border: solid 1px black;font-weight:lighter'\n",
    "    mytable = page_content.find_all('table', attrs={'style':table_style})\n",
    "    # Usually it will be a list, take the first element\n",
    "    mytable = mytable[0]\n",
    "    # Get each row of result table\n",
    "    rows = mytable.find_all('tr', attrs={'style':'font-size:12px;'})\n",
    "    result = []\n",
    "    for row in rows:\n",
    "        cols = list(row.children)\n",
    "        result.append({\n",
    "            'cid':cid,\n",
    "            'cname':cname,\n",
    "            'O.S.N.':cols[0].text,\n",
    "            'Candidate':cols[1].text,\n",
    "            'Party':cols[2].text,\n",
    "            'EVM Votes':cols[3].text,\n",
    "            'Postal Votes':cols[4].text,\n",
    "            'Total Votes':cols[5].text,\n",
    "            'PctVotes':cols[6].text\n",
    "        })\n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that is reusable.\n",
    "# This extracts data for single state\n",
    "def scraper(base_url, constituencyid, output_path, known_cid):\n",
    "    for cid in sorted(constituencyid):\n",
    "        if cid in known_cid:\n",
    "            continue\n",
    "        print(\"Processing {}:{}\".format(cid, constituencyid[cid]), \" \"*40, end='\\r')\n",
    "        url = generate_url(base_url, cid)\n",
    "        page_content = download_page(url)\n",
    "        result = parse_content(page_content, cid, constituencyid[cid])\n",
    "        if len(result) > 0:\n",
    "            with open(output_path, 'a') as f:\n",
    "                result.to_csv(f, header=f.tell() == 0, index=False)\n",
    "        # Take time between requests\n",
    "        sleep(waitTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituencyid = build_constituencyid(state_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing state: West Bengal, No: Constituency: 292, output_file: Data/West Bengal.csv\n",
      "Processing 294:Murarai                                                     \r"
     ]
    }
   ],
   "source": [
    "# Process all states\n",
    "states = list(state_id)\n",
    "# Override with manual selected states\n",
    "states = ['West Bengal']\n",
    "for state in states:\n",
    "    filename = r\"{}.csv\".format(state)\n",
    "    output_path = os.path.join('Data', filename)\n",
    "    print(\"Processing state: {}, No: Constituency: {}, output_file: {}\".format(\n",
    "                                    state, len(constituencyid[state]), output_path))\n",
    "    known_cid = set()\n",
    "    if os.path.exists(output_path):\n",
    "        data = pd.read_csv(output_path)\n",
    "        known_cid = set(data['cid'].unique())\n",
    "    scraper(state_id[state]['url'], constituencyid[state], output_path, known_cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
